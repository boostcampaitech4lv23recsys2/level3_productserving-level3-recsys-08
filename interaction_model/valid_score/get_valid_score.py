import os
import sys
import pandas as pd
from tqdm import tqdm
import numpy as np
import random
from args import parse_args
from scipy import sparse
from scipy.sparse import csr_matrix, lil_matrix
import implicit
import annoy
sys.path.append('../..')
from Utils import model_recommend_movies
from interaction_model import Inference



def get_data(args) -> pd.DataFrame:
    """MBTIì™€ movielensì— ê³µí†µìœ¼ë¡œ ìˆëŠ” ì˜í™”ì˜ interaction ë°ì´í„°í”„ë ˆì„ì„ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜ì´ë‹¤.

    Args:
        args

    Returns:
        ratings (DataFrame): movieì™€ movielensì— ê³µí†µì ìœ¼ë¡œ ìˆëŠ” ì˜í™”ì˜ interaction ë°ì´í„°í”„ë ˆì„
                             shape = (ì•½ 1157ë§Œ, 4) columns = ['userId','movieId','rating','timestamp']
    """
    # raw ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
    data_path = args.data_path
    ratings = pd.read_csv(data_path+'ml-25m/ratings.csv')
    inter_mbti_ml_title_movieid = pd.read_csv(data_path+"inter_mbti_ml_title_movieId.csv")

    # mbtiì™€ movielensì— ê³µí†µìœ¼ë¡œ ìˆëŠ” ì˜í™”ì— ëŒ€í•œ interactionë§Œ ê³ ë ¤
    inter_mbti_ml_movieid = list(inter_mbti_ml_title_movieid['movieId'].values)
    ratings = ratings[ratings['movieId'].isin(inter_mbti_ml_movieid)]
    
    return ratings


def split_train_test(ratings:pd.DataFrame, test_user_ratio:float = 0.1) -> pd.DataFrame:
    """ìœ ì €ë¥¼ test_ratioì— ë§ê²Œ ëœë¤í•˜ê²Œ ë‚˜ëˆˆ í›„, ë‚˜ëˆ ì§„ ìœ ì €ì˜ ì¸í„°ë ‰ì…˜ì„ train_df, test_dfë¡œ ë¦¬í„´í•˜ëŠ” í•¨ìˆ˜

    Args:
        ratings (DataFrame): ì „ì²´ ìœ ì €ì˜ interaction ë°ì´í„°í”„ë ˆì„
        test_user_ratio (float, optional): ì „ì²´ ìœ ì €ì¤‘ test ìœ ì €ì˜ ë¹„ìœ¨, Defaults to 0.1.

    Returns:
        train_df (DataFrame): train ìœ ì €ì˜ interactionì´ ë‹´ê¸´ ë°ì´í„°í”„ë ˆì„
        test_df (DataFrame): test ìœ ì €ì˜ interactionì´ ë‹´ê¸´ ë°ì´í„°í”„ë ˆì„
    """
    # userë¥¼ ë¹„ìœ¨ì— ë§ê²Œ ë‚˜ëˆ„ê¸° (list)
    user_list = list(ratings['userId'].unique())
    test_size = int(len(user_list) * test_user_ratio)
    test_user = random.sample(user_list, test_size)
    train_user = list(set(user_list)-set(test_user))

    # train_dfì—ëŠ” train userë§Œ, test_dfì—ëŠ” test userë§Œì˜ interaction ë°ì´í„°í”„ë ˆì„ ë§Œë“¤ê¸° (DataFrame)
    train_df = ratings[ratings['userId'].isin(train_user)]
    test_df = ratings[ratings['userId'].isin(test_user)]

    # í˜¹ì‹œëª°ë¼ í˜„ì¬ í´ë”ì— ì €ì¥
    train_df.to_csv("train_df.csv", index=False)
    test_df.to_csv("test_df.csv", index=False)
    
    return train_df, test_df


def get_als_embedding_vector(args, train_df:pd.DataFrame) -> np.array:
    """interaction ì •ë³´ê°€ ë‹´ê¸´ Dataframeì´ ë“¤ì–´ì˜¤ë©´, ì•„ì´í…œì— ëŒ€í•œ ì„ë² ë”© ë²¡í„°ë¥¼ ë¦¬í„´í•˜ëŠ” í•¨ìˆ˜

    Args:
        args
        train_df (DataFrame): train ìœ ì €ì˜ interactioinì´ ë‹´ê¸´ ë°ì´í„°í”„ë ˆì„

    Returns:
        item_vecs (array): itemì˜ ì„ë² ë”©ë²¡í„°, shape=(item ê°œìˆ˜, ì„ë² ë”© ì°¨ì›)
    """
    if 'timestamp' in train_df.columns:
        train_df.drop(columns = "timestamp",inplace = True)
    train_df['rating'] = 1

    user2idx = {k:v for v,k in enumerate(train_df['userId'].unique())}
    item2idx = {k:v for v,k in enumerate(train_df['movieId'].unique())}
    idx2item = {v:k for v,k in enumerate(train_df['movieId'].unique())}

    train_df['useridx'] = train_df['userId'].map(user2idx) # userId -> ì¸ë±ìŠ¤ë¡œ ë°”ê¿”ì¤ë‹ˆë‹¤.
    train_df['movieidx'] = train_df['movieId'].map(item2idx) # movieId -> ì¸ë±ìŠ¤ë¡œ ë°”ê¿”ì¤ë‹ˆë‹¤.

    sparse_user_item = sparse.csr_matrix((train_df['rating'].astype(float),
                                        (train_df['useridx'], train_df['movieidx']))) # csr_matrix ìƒì„±

    als_model = implicit.als.AlternatingLeastSquares(
                                    factors = args.embed_size,
                                    regularization = args.als_regularization,
                                    iterations = args.als_iterations,
                                    calculate_training_loss = False,
                                    use_gpu = True
                                ) # ëª¨ë¸ init

    als_model.fit(sparse_user_item) # í•™ìŠµ
    item_vecs = als_model.item_factors.to_numpy() # item vectorë§Œ ë¹¼ì˜µë‹ˆë‹¤.

    return item_vecs


def create_annoy_model(args, train_df:pd.DataFrame, item_vecs) -> None:
    """item ì„ë² ë”© ë²¡í„°ë¥¼ ë°›ì€ í›„ ë²¡í„°ì˜ ìœ ì‚¬ë„ë¥¼ í•™ìŠµí•œ annoy ëª¨ë¸ì´ í˜„ì¬ í´ë”ì— ì €ì¥ëœë‹¤.

    Args:
        args
        train_df (DataFrame): train ìœ ì €ì˜ interactioinì´ ë‹´ê¸´ ë°ì´í„°í”„ë ˆì„
        item_vecs (np.array): (ì•„ì´í…œ ê°œìˆ˜, ì„ë² ë”© ë²¡í„°ì°¨ì›)ì˜ í¬ê¸°ë¥¼ ê°–ëŠ” array
    """
    data_path = args.data_path
    inter_mbti_ml_title_movieid = pd.read_csv(data_path+"inter_mbti_ml_title_movieId.csv")

    user2idx = {k:v for v,k in enumerate(train_df['userId'].unique())}
    item2idx = {k:v for v,k in enumerate(train_df['movieId'].unique())}
    idx2item = {v:k for v,k in enumerate(train_df['movieId'].unique())}

    # inter_mbti_ml_title_movieidë„ ì¸ë±ì‹±ì²˜ë¦¬
    inter_mbti_ml_title_movieid['movieidx'] = inter_mbti_ml_title_movieid['movieId'].map(item2idx)
    inter_mbti_ml_title_movieid.dropna(inplace = True)
    inter_mbti_ml_title_movieid['movieidx'] = inter_mbti_ml_title_movieid['movieidx'].astype(int)

    # annoy ëª¨ë¸
    similar_items_index = annoy.AnnoyIndex(args.embed_size,'angular') #'angular','euclidean','manhattan','hamming'
    n_trees = args.annoy_n_trees
    for idx in inter_mbti_ml_title_movieid['movieidx']:
        similar_items_index.add_item(idx2item[idx],item_vecs[idx]) # idx -> movieIdë¡œ ë°”ê¿”ì„œ annoyì— ì €ì¥í•©ë‹ˆë‹¤.
    similar_items_index.build(n_trees)
    similar_items_index.save(f"ALS_angular_{args.embed_size}") #annoy ëª¨ë¸ ì €ì¥


def get_test_user_prefer_info(test_df:pd.DataFrame) -> dict:
    """test ìœ ì €ì˜ ì¸í„°ë ‰ì…˜ì´ ë‹´ê¸´ ë°ì´í„°í”„ë ˆì„ì„ ë°›ìœ¼ë©´, ê° test ìœ ì €ê°€ ì„ í˜¸í•œ ì˜í™” ë¦¬ìŠ¤íŠ¸ë¥¼ dictí˜•ìœ¼ë¡œ ë¦¬í„´í•˜ëŠ” í•¨ìˆ˜

    Args:
        test_df (DataFrame): test ìœ ì €ì˜ ì¸í„°ë ‰ì…˜ì´ ë‹´ê¸´ ë°ì´í„°í”„ë ˆì„

    Returns:
        test_user_movie_dict: testìœ ì €ê°€ ì„ í˜¸í•œ ì˜í™”ì •ë³´ dict
                              {user1:[item1, item2], ...}ì˜ í˜•ì‹ìœ¼ë¡œ ë‹´ê²¨ì ¸ìˆë‹¤.
    """
    # if test_df == None:
    #     pd.read_csv("./test_df")
    
    grouped = test_df.groupby('userId')
    test_user_movie = grouped['movieId'].apply(list)

    test_user_movie_dict = dict(test_user_movie)

    return test_user_movie_dict


def calculate_valid_score(args, test_user_movie_dict:dict, model_name:str, valid_ratio:float=0.5) -> float:
    """test ìœ ì €ê°€ ì„ í˜¸í•˜ëŠ” ì˜í™” ì •ë³´ dictë¥¼ ë°›ìœ¼ë©´, ê° ì˜í™”ë³„ 10ê°œì”© ì¶”ì²œë°›ì€ í›„ valid score ê³„ì‚°í•´ì£¼ëŠ” í•¨ìˆ˜

    Args:
        args
        test_user_movie_dict (dict): ê° test ìœ ì €(key)ê°€ ì„ í˜¸í•œ ì˜í™” ë¦¬ìŠ¤íŠ¸(value)ë¥¼ ë‹´ì€ dict
        model_name (string): í•™ìŠµëœ annoy ëª¨ë¸ ê²½ë¡œ
        valid_ratio (float, optional): ìœ ì €ê°€ ì„ í˜¸í•œ ì˜í™”ë“¤ ì¤‘ ê²€ì¦ì— ì‚¬ìš©í•  valid ë¹„ìœ¨

    Returns:
        score (float): valid scoreì˜ í‰ê· , í‘œì¤€í¸ì°¨
    """
    scores = []
    for user, movie_list in tqdm(test_user_movie_dict.items()):
        movie_list_len = len(movie_list)
        user_prefer_movieids = random.sample(movie_list, int(movie_list_len*(1-valid_ratio)))     # inference ì…ë ¥ ì˜í™” id list
        user_valid_movieids = list(set(movie_list) - set(user_prefer_movieids)) # valid ì˜í™” id list
        user_rec_movieids = model_recommend_movies("INFP","5w4",user_prefer_movieids,10,model_name) #ì¶”ì²œ ì˜í™” id list
        inter_cnt = len(set(user_valid_movieids) & set(user_rec_movieids))      # valid ì˜í™”ì™€ ì¶”ì²œ ì˜í™” êµì§‘í•© ê°œìˆ˜
        score = inter_cnt / len(user_valid_movieids)                            # valid ì˜í™” ê°œìˆ˜
        scores.append(score)
    
    return np.mean(scores), np.std(scores)


def get_valid_score(args, data:str=None):
    """ë¬´ë¹„ë Œì¦ˆì™€ MBTIì— ê³µí†µìœ¼ë¡œ ìˆëŠ” ì•„ì´í…œì— ëŒ€í•œ interaction íŒŒì¼ ê²½ë¡œë¥¼ ì…ë ¥ë°›ìœ¼ë©´, valid scoreë¥¼ ë¦¬í„´í•˜ëŠ” í•¨ìˆ˜

    Args:
        data (str, optional): ë¬´ë¹„ë Œì¦ˆì™€ MBTIì— ê³µí†µìœ¼ë¡œ ìˆëŠ” ì•„ì´í…œì— ëŒ€í•œ interactionì´ ë‹´ê¸´ ë°ì´í„°í”„ë ˆì„ì˜ ê²½ë¡œ
                              ë°ì´í„°í”„ë ˆì„ì˜ columnì— 'userId','movieId','rating'ê°€ ë“¤ì–´ê°€ìˆì–´ì•¼í•œë‹¤.
    Returns:
        score (float): valid scoreì˜ í†µê³„ëŸ‰(í‰ê· , í‘œì¤€í¸ì°¨)
    """
    random.seed(args.seed)
    
    if data:
        data = pd.read_csv(data)
    else:
        print("dataê°€ ì—†êµ°ìš”~ data ìƒì„± ì‹œì‘!")
        data = get_data(args)
        print("data ìƒì„± ì™„ë£Œ!")
    
    # train_df = pd.read_csv('./train_df.csv')
    # test_df = pd.read_csv('./test_df.csv')

    train_df, test_df = None, None
    train_df, test_df = split_train_test(data, test_user_ratio=args.test_user_ratio)
    print("data ë‚˜ëˆ„ê¸° ì™„ë£Œ!")


    print("ê° ì•„ì´í…œì˜ embedding vector ë½‘ê¸° ì‹œì‘!")
    item_vecs = get_als_embedding_vector(args, train_df)
    print("ê° ì•„ì´í…œì˜ embedding vector ë½‘ê¸° ì™„ë£Œ!")
    
    create_annoy_model(args, train_df, item_vecs)
    ("ğŸ˜¡annoy ëª¨ë¸ ìƒì„± ì™„ë£Œ!")

    test_user_movie_dict = get_test_user_prefer_info(test_df)
    print("test ìœ ì €ì˜ ì„ í˜¸ì •ë³´ ë½‘ê¸° ì™„ë£Œ!")

    print("valid score ê³„ì‚° ì‹œì‘!")
    score_mean, score_std = calculate_valid_score(args, test_user_movie_dict, args.model_name, args.valid_ratio)
    print("valid score ê³„ì‚° ì™„ë£Œ!")

    print(f'test_ìœ ì €ì˜ valid ìŠ¤ì½”ì–´ì˜ í‰ê· : {score_mean}')
    print(f'test_ìœ ì €ì˜ valid ìŠ¤ì½”ì–´ì˜ í‘œì¤€í¸ì°¨: {score_std}')

    return score_mean, score_std

if __name__ == "__main__":
    args = parse_args()
    args.data_path = "/opt/ml/input/fighting/CSV/"

    get_valid_score(args)