import os
import json
import argparse
import pandas as pd
import numpy as np
import time, datetime
from tqdm import tqdm
from logging import getLogger
from args import parse_args
import torch
import mlflow
from recbole.quick_start import run_recbole
import wandb
from pathlib import Path
from feature_engineering import FE
from util import inference, make_dataset, make_config, mvti_recommend

# í•„ìˆ˜
# python train.py --model_name [] --config []

def main(args):
    """ëª¨ë¸ train, inference íŒŒì¼

    args:
        model_name(default - "EASE") : ëª¨ë¸ì˜ ì´ë¦„ì„ ì…ë ¥ë°›ìŠµë‹ˆë‹¤.

        infer(default - False) : 
            Trueì¼ ê²½ìš° submissionì„ ì €ì¥í•©ë‹ˆë‹¤.
            inference ê³¼ì •ì´ ëŠë¦¬ê¸° ë•Œë¬¸ì— í•„ìš”ì—†ë‹¤ë©´ Falseë¡œ í•˜ëŠ”ê²Œ ì¢‹ìŠµë‹ˆë‹¤.

        dataset_name(default - "train_data) : ë°ì´í„°ì…‹ì˜ ì´ë¦„ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.

        config_name(default - "basic_config.yaml") : config ì •ë³´ê°€ ë‹´ê¸´ yaml íŒŒì¼ ì´ë¦„ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.
        ğŸ”¥ğŸ”¥ğŸ”¥ ì£¼ì˜ )) ëª¨ë¸ì´ ì—¬ëŸ¬ ì¢…ë¥˜ì´ê¸° ë•Œë¬¸ì—, ì‚¬ìš©í•˜ëŠ” ëª¨ë¸ì— ë§ì¶°ì„œ config íŒŒì¼ ì´ë¦„ì„ ê¼­ ì…ë ¥í•´ì£¼ì„¸ìš” â€¼ï¸
        
        topk(default - 10) : inferenceë¥¼ í•  ê²½ìš°ì— submissionì— ìœ ì €ë§ˆë‹¤ ëª‡ ê°œì˜ ì•„ì´í…œì„ ì¶”ì²œí• ì§€ ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

        ë‚˜ë¨¸ì§€ëŠ” hyper parameter ì…ë‹ˆë‹¤. 
    """
    ## MLflow 
    remote_server_uri="http://101.101.219.178:30005"
    mlflow.set_tracking_uri(remote_server_uri)

    # âœ¨ sequential model âœ¨
    seq_list = ['FPMC', 'GRU4Rec', 'NARM', 'STAMP', 'Caser', 'NextItNet', 'TransRec', 'SASRec',
                 'BERT4Rec', 'SRGNN', 'GCSAN','GRU4RecF', 'SASRecF', 'FDSA', 'S3Rec']
    
    model_name = args.model_name
    infer = args.inference
    config_name = args.config
    top_k = args.top_k
    dataset_name = args.dataset_name
    
    # Set MLflow Experiment
    client = mlflow.tracking.MlflowClient()
    experiment_name = model_name # "EASE" # experiment ì´ë¦„
    try:
        experiment_id = client.create_experiment(experiment_name)
    except:
        experiment = client.get_experiment_by_name(experiment_name)
        experiment_id = experiment.experiment_id

    # datasetì´ í•˜ë‚˜ë¼ë„ ì—†ì„ ê²½ìš° ìƒì„±
    # if (not os.path.isfile(f'./dataset/{dataset_name}/{dataset_name}.inter')) or\
    #     (not os.path.isfile(f'./dataset/{dataset_name}/{dataset_name}.item')) or\
    #     (not os.path.isfile(f'./dataset/{dataset_name}/{dataset_name}.user')):
    #     print("Make dataset...")
    #     make_dataset(dataset_name)

    # config íŒŒì¼ì´ ì—†ì„ ê²½ìš° ìƒì„±                
    if not os.path.isfile(f'./{config_name}'):
        print("Make config...")
        make_config(config_name)

    parameter_dict = args.__dict__
   
    # Default eval_argsë¥¼ ì €ì¥
    if model_name not in seq_list:
        parameter_dict['eval_args'] = {
            'split': {'RS': [9, 1, 0]},
            'group_by': 'user',
            'order': 'RO',
            'mode': 'full',}
    
    # Sequential ëª¨ë¸ì¼ ê²½ìš° eval_argsì™€ loss_typeì„ ë³€ê²½
    if model_name in seq_list:
        parameter_dict['eval_args'] = {
            'split': {'RS': [9, 1, 0]},
            'group_by': 'user',
            'order': 'TO',
            'mode': 'full',}
    #     parameter_dict['loss_type'] = 'BPR'
    
    # inferenceê°€ í•„ìš”í•œ ëª¨ë¸ì¼ ê²½ìš° 1:0:0 í•™ìŠµ ë³€ê²½
    # if infer:
    #     parameter_dict['eval_args']['split'] = {'RS' : [1,0,0]}
    
    print(f"running {model_name}...")
    result = run_recbole(
        model = model_name,
        dataset = dataset_name,
        config_file_list = [config_name],
        config_dict = parameter_dict,
    )
    
    # model_nameì´ ë“¤ì–´ê°€ëŠ” pth íŒŒì¼ ì¤‘ ìµœê·¼ì— ìƒì„±ëœ ê±¸ë¡œ ë¶ˆëŸ¬ì˜´
    os.makedirs('saved',exist_ok=True)
    save_path = os.listdir('./saved')
    model_path = './saved/' + sorted([file for file in save_path if model_name in file ])[-1]
    model_path_absolute = Path(model_path).absolute()

    run_name=model_name
    desc=f"Model path: {model_path_absolute}"
    with mlflow.start_run(run_name=run_name, description=desc, experiment_id=experiment_id) as run:
        for metric, score in result['best_valid_result'].items():
            print(metric,score)
            mlflow.log_metric(metric.replace('@','.'), score)
    print(result)
    wandb.run.finish()

    if infer:
        mvti_recommend(model_name,top_k)
    
if __name__ == "__main__":
    args = parse_args()
    main(args)